{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring dimlpfidex with OmniXAI for heart attack prediction\n",
    "\n",
    "**Introduction:**\n",
    "\n",
    "Welcome to HES-Xplain, our interactive platform designed to facilitate explainable artificial intelligence (XAI) techniques. In this use case, we use the [Heart Attack Analysis & Prediction Dataset](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset). This notebook is going to showcase how to use the MLXplain (OmniXAI) integration of [DimlpBT](https://hes-xplain.github.io/documentation/dimlpfidex/dimlp/dimlpbt/), [Fidex](https://hes-xplain.github.io/documentation/dimlpfidex/fidex/fidex/) & [FidexGloRules](https://hes-xplain.github.io/documentation/dimlpfidex/fidex/fidexglorules/).\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "    1. Observe a different use case where XAI can be used.\n",
    "    2. Understand how to pre-process data.\n",
    "    3. Understand how to use Dimlp and Fidex with OmniXAI.\n",
    "    4. Showcase the versatility of HES-Xplain using a different dataset.\n",
    "    5. Provide practical insights into applying Dimlp and Fidex to heart attack prediction through an interactive notebook.\n",
    "    6. Foster a community of XAI enthusiasts and practitioners.\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "    1. Dataset and Problem Statement.\n",
    "    2. Load and pre-process the dataset.\n",
    "    3. Train the Model.\n",
    "    4. Local and global rules generation & OmniXAI dashboard display.\n",
    "    6. Conclusion.\n",
    "    7. References.\n",
    "\n",
    "Through this use case, we aim to show the users the potential of Dimlp and Fidex as tools for transparent and interpretable classification. With HES-Xplain, we make XAI accessible, helping users build trust in their models and make informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Problem Statement\n",
    "The dataset we'll be working with is called the [Heart Attack Analysis & Prediction Dataset](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset) and is accessible on [Kaggle](https://www.kaggle.com). It comprises 303 anonymized data records containing health information. In this notebook, our focus is predicting the risk of heart attack based on all given factors. By leveraging deep learning techniques and Fidex algorithms, we aim to not only achieve high classification performance but also gain insights into the attributes (pixels here) that contribute to the classification decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and pre-process the dataset.\n",
    "Let's start by preprocessing the data. We categorize the cp attribtue and the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "from omnixai.data.tabular import Tabular\n",
    "from omnixai.visualization.dashboard import Dashboard\n",
    "from omnixai.explainers.tabular.auto import TabularExplainer\n",
    "from mlxplain.explainers.tabular.specific.dimlpfidex import DimlpBTModel\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "cp = pd.get_dummies(\n",
    "    dataset[\"cp\"], prefix=\"cp\", prefix_sep=\"_\", columns=[\"cp\"], dtype=\"int8\"\n",
    ")\n",
    "dataset = pd.concat([dataset.iloc[:, :2], cp, dataset.iloc[:, 3:]], axis=1)\n",
    "dataset = dataset.rename(\n",
    "    columns={\n",
    "        \"cp_0\": \"cp_typical\",\n",
    "        \"cp_1\": \"cp_atypical\",\n",
    "        \"cp_2\": \"cp_nonanginal \",\n",
    "        \"cp_3\": \"cp_asymptomatic\",\n",
    "    }\n",
    ")\n",
    "\n",
    "output = pd.get_dummies(\n",
    "    dataset[\"output\"], prefix=\"risk\", prefix_sep=\"_\", columns=[\"output\"], dtype=\"int8\"\n",
    ")\n",
    "\n",
    "dataset = pd.concat([dataset.iloc[:, :-1], output], axis=1)\n",
    "dataset = dataset.rename(columns={\"risk_0\": \"risk_no\", \"risk_1\": \"risk_yes\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must split the dataset into a train and test subsets and write feature names in a file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(frac=1)\n",
    "split = int(dataset.shape[0] * 0.8)\n",
    "\n",
    "features = dataset.columns\n",
    "\n",
    "nb_classes = 2\n",
    "nb_features = len(features) - nb_classes\n",
    "\n",
    "train_dataset = Tabular(\n",
    "    data=dataset.iloc[:split,:]\n",
    ")\n",
    "\n",
    "test_dataset = Tabular(\n",
    "    data=dataset.iloc[split:,:]\n",
    ")\n",
    "\n",
    "root_dir = pl.Path(\"out\")\n",
    "root_dir.mkdir(parents=True, exist_ok=True)\n",
    "features_filename = \"attributes.txt\"\n",
    "\n",
    "with open(root_dir.joinpath(features_filename), \"w\") as file:\n",
    "    for feature in features:\n",
    "        file.write(f\"{feature}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model.\n",
    "Let's train the [DimlpBT](https://hes-xplain.github.io/documentation/dimlpfidex/dimlp/dimlpbt/) model with our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING: verbose_console can't be used when used in notebooks for some reason\n",
    "\n",
    "model = DimlpBTModel(\n",
    "    root_dir,\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    nb_features,\n",
    "    nb_classes,\n",
    "    attributes_file=features_filename,\n",
    ")\n",
    "\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local and global rules generation & OmniXAI dashboard display.\n",
    "The rule extraction must now be initialized and executed with Fidex & FidexGloRules to generate local & global explainations. Then, we display the explanations on the OmniXAI dashboard :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x77ddf95f3f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-27 16:59:20,596] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/flask/app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/flask/app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/flask/app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/flask/app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/dash/dash.py\", line 1373, in dispatch\n",
      "    ctx.run(\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/dash/_callback.py\", line 465, in add_context\n",
      "    output_value = _invoke_callback(func, *func_args, **func_kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/dash/_callback.py\", line 40, in _invoke_callback\n",
      "    return func(*args, **kwargs)  # %% callback invoked %%\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/omnixai/visualization/callbacks/local_exp.py\", line 36, in change_parameters\n",
      "    params[\"display_instance\"] = int(instance)\n",
      "                                 ^^^^^^^^^^^^^\n",
      "TypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\n",
      "[2024-08-27 16:59:20,612] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/flask/app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/flask/app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/flask/app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/flask/app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/dash/dash.py\", line 1373, in dispatch\n",
      "    ctx.run(\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/dash/_callback.py\", line 465, in add_context\n",
      "    output_value = _invoke_callback(func, *func_args, **func_kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/dash/_callback.py\", line 40, in _invoke_callback\n",
      "    return func(*args, **kwargs)  # %% callback invoked %%\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jean-marc/Documents/mlxplain/.venv/lib/python3.11/site-packages/omnixai/visualization/callbacks/local_exp.py\", line 45, in update_view\n",
      "    params = json.loads(data)\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/json/__init__.py\", line 339, in loads\n",
      "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
      "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 10\n",
    "min_covering = 2\n",
    "max_failed_attempts = 15\n",
    "min_fidelity = 1.0\n",
    "lowest_fidelity_allowed = 0.9\n",
    "use_minimal_version = True\n",
    "\n",
    "explainer = TabularExplainer(\n",
    "        explainers=[\"fidex\", \"fidexGloRules\"],\n",
    "        data=train_dataset,\n",
    "        model=model,\n",
    "        mode=\"classification\",\n",
    "        params={\n",
    "            \"fidex\": {\n",
    "                \"max_iterations\": max_iterations,\n",
    "                \"attributes_file\": features_filename,\n",
    "                \"min_covering\": min_covering,\n",
    "                \"max_failed_attempts\": max_failed_attempts,\n",
    "                \"min_fidelity\": min_fidelity,\n",
    "                \"lowest_min_fidelity\": lowest_fidelity_allowed,\n",
    "            },\n",
    "\n",
    "            \"fidexGloRules\": {\n",
    "                \"heuristic\": 1,\n",
    "                \"with_fidexGlo\": True,\n",
    "                \"fidexGlo\": {\n",
    "                    \"attributes_file\": features_filename,\n",
    "                    \"with_minimal_version\": use_minimal_version,\n",
    "                    \"max_iterations\": max_iterations,\n",
    "                    \"min_covering\": min_covering, \n",
    "                    \"covering_strategy\": True,\n",
    "                    \"max_failed_attempts\": max_failed_attempts,\n",
    "                    \"min_fidelity\": min_fidelity, \n",
    "                    \"lowest_min_fidelity\": lowest_fidelity_allowed, \n",
    "                },\n",
    "                \"attributes_file\": features_filename,\n",
    "                \"nb_threads\": 4,\n",
    "                \"with_minimal_version\": use_minimal_version,\n",
    "                \"max_iterations\": max_iterations,\n",
    "                \"min_covering\": min_covering,\n",
    "            }\n",
    "        },\n",
    ")\n",
    "local_explainations = explainer.explain(X=test_dataset)\n",
    "global_explainations = explainer.explain_global()\n",
    "\n",
    "dashboard = Dashboard(local_explanations=local_explainations, global_explanations=global_explainations)\n",
    "dashboard.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
